# How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs

一个高速处理器可能以不同于程序制定顺序的方式执行操作。如果处理器满足如下的规则，执行的正确性就能得到保证：如果执行的结果与按照程序制定顺序执行的相同。一个满足该条件的处理器就称为可顺序化的。
考虑一台计算机，其包含几个可顺序化的处理器并且共享一个内存。在这样的计算机上，设计并证明一个多处理器算法的正确性的习惯方法都遵循如下的条件：执行的结果与所有处理器的操作以某种总的顺序执行相同，并且总的顺序上其中每个处理器的操作与该处理器上程序制定的顺序相同。满足该条件的多处理器系统称为顺序一致性。每个处理器的顺序性并不能保证整个多处理器计算机的顺序一致性。在这篇简短的文章中，我们描述了一种方法（后面可以看到该方法是针对处理器与内存设计的），其能确保在共享内存且互相通信的多个顺序处理器上的顺序一致性。

我们假设计算机有一组进程和内存模块组成，进程之间只能通过内存通信。我们唯一关心的处理器操作是向内存模块发送读取与写入请求。我们假设每个处理器按顺序发送这些请求（上一个请求没有处理完则等待）。

我们通过考虑一个2进程的互斥锁协议来展示这一问题。每个进程都包含一个临界区（critical section），协议的目的就是保证在任何时刻都只有一个进程能执行临界区代码。协议如下：

```
process 1
	a := 1;
	if b = 0 then critical section;
					a := 0;
			 else ... fi

process 2

	b := 1;
	if a = 0 then critical section;
					b := 0;
			 else ... fi
```

else语句中包含一些机制来保证最终能执行临界区代码，但是这些与我们的讨论无关。很容易证明该协议保证了临界区的互斥访问。因此，当这个2进程的程序在一个顺序一致性的多处理
器上执行的时候，这两个处理器不能同时执行临界区代码。

我们首先观察到一个顺序处理器可以用任意的顺序执行进程1的“a:= 1”(这里找到的pdf上是b:=1，应是错误)与 “fetch b"操作（当仅从进程1的程序角度来看待的话，它并不关心这两个操作的执行顺序）。
然而，很容易看到如果先执行"fetch b"操作将会导致错误--两个进程同时执行了临界区。这启发我们关于多处理器计算机的第一个要求：

要求 R1: 每个处理器都按照程序指定的顺序发送内存请求。

但是事实上由于value的store只有在这个value已经被计算出来的时候才能进行，因此要满足R1实际是很复杂的。处理器在发出一个value的内存fetch请求的时候，需要确保针对该value前一个store请求已经处理完成。为了最小化等待，处理器可以向内存模块发送写入请求而不需要知道将要写入的值（结合后面的请求队列，可以理解为队列占位）。

要求R1是不足以保证执行正确性的。为了说明这一点，假设每个内存模块有多个端口，每个端口服务于一个处理器。让我们考虑
将a与b的值写入不同的内存模块中，并且遵循如下的操作顺序：

1. 处理器1向内存模块1发送a:=1的写入请求。内存模块1当前正忙于执行其他处理器的请求。

2. 处理器1向内存模块2上相应的端口发送“fetch b”的请求。该内存模块空闲并且立刻执行了该请求。

3. 处理器2发送b:=1请求到内存模块2. 这个请求将会在处理器1的“fetch b”请求完成之后被处理。

4. 处理器2发送“fetch a”请求到内存模块1的相应端口上。该模块依旧忙中。

现在内存模块1上有两个请求等待执行。如果处理器2的“fetch a”操作先被执行，那么两个处理器会同时进入临界区，协议失效。
如果内存模块采用一种轮转调度算法来一次处理器每个端口上的请求的话，这中情况是可能会发生的。

这种情况下，只有内存模块1的两个请求没有一他们被接收到的顺序执行的话，错误才会发生。这启发我们如下的要求：

要求R2:一个内存模块接收到所有处理器请求必须以FIFO的顺序被处理。发送内存请求就是将内存请求置入请求队列。

要求R1意味着一个处理器只有在上一个请求进入内存模块请求队列之后才能发送一下个内存请求。因此，如果队列满，其必须等待。
如果有两个或者多个处理器试图同时将请求放入同一个队列，他们的顺序并不重要。

注意，如果某个读取请求的内存位置上有一个在队列中等待的写入请求，那么这个读取请求就不需要放入队列，它只需要从
最后一个写入请求中读取就可以了。

要求R1与R2保证了如果单个处理器是可顺序化的，那么整个多处理器计算机就是顺序一致的。为了说明这一点
，首先在内存请求上引入关系$$\rightarrow$$如下。定义$$A \rightarrow B$$当且仅当: 1)A与B是由同一个
处理器发送且A先于B(因此执行也会A先于B),2）A与B是发往同一个内存模块的，且A先于B进入队列. 很容易看到要求R1与R2意味着$$\rightarrow$$是内存请求上的
偏序关系。根据每个处理器的顺序性，可以证明如下的结论：无论所有操作以什么样的sequential顺序执行，针对同一个value的store和fetch操作，如果A->B，就一定意味着A在B之前执行.
(注:如果A和B是同一个处理器产生的，那么A在B之前产生，根据R1 从程序描述上A也一定是在B之前，由于它们操作的都是同一个value，那么肯定是在同一个内存模块，那么肯定是A先进入该内存模块的请求队列，那么也一定是A先执行；如果A和B是不同处理器产生的，根据A->B的定义，那么A也肯定是在B之前执行。另外A->B如果它们操作的是不同的value，是无法保证A一定在B之前执行的，因为它们可能是位于不同的内存模块，而分属不同内存模块的请求，在R1 R2成立的情况下，谁先执行也是没有定义的，同时谁先执行也不影响sequential consistent)。这反过来又证明了多处理器系统的sequential consistent。





